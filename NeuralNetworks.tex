\documentclass[12pt,a4]{article}
\usepackage[ngerman]{babel}
\usepackage{bibgerm}
\usepackage{csquotes}
\usepackage{hyperref}
\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{qrcode}
\usepackage{subcaption}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric}

\usepackage{imakeidx}

\title{\textbf{Proseminar\\Künstliche neuronale Netze\\Deep Convolutional Neural Networks}}
\author{Jens Ostertag}
\date{\today}

\lstset{
basicstyle=\fontsize{10}{10}\selectfont\ttfamily
}

\renewcommand*\contentsname{Inhaltsverzeichnis}

\makeindex

\begin{document}
\maketitle
\tableofcontents
\clearpage
\section{Computer lernen lassen}\label{sec:Introduction}
\textit{Künstliche Intelligenz}, \textit{Maschinelles Lernen} und \textit{Neuronale Netze} - Alle diese Begriffe sind gewissermaßen miteinander verbunden, denn ihre Technik beruht darauf, dass Computer lernen können. Vor einem tieferen Einblick möchte ich diese Begriffe jedoch einordnen und differenzieren.

Bei einem \textit{künstlichen neuronalen Netz}\index{Neuronales Netz} handelt es sich um die Simulation des menschlichen Gehirns. Neuronale Netze sind die Grundlage für alles, das Lernen kann oder Entscheidungen treffen soll.

\textit{Maschinelles Lernen}\index{Maschinelles Lernen} beschreibt das Lernen eines solchen neuronales Netzes. Wie auch der Mensch, ist ein künstliches neuronales Netz in der Lage, sich unterschiedliche Fähigkeiten anzueignen, unabhängig von der Komplexität der jeweiligen Aufgabe. Dadurch wird beispielsweise ermöglicht, dass ein Computer Bilder erkennt und klassifiziert oder die Position bestimmter Objekte darin bestimmen kann.

Die \textit{künstliche Intelligenz}\index{Künstliche Intelligenz} ist die undefinierteste Form neuronaler Netze, was auch damit zusammenhängt, dass es keine sehr genaue Definition von Intelligenz gibt. Ist man intelligent, wenn man schnell rechnen kann? Somit ist bereits ein simpler Taschenrechner von vor 40 Jahren äußerst intelligent. Oder bedeutet Intelligenz, dass man selbstständig denken und fühlen können muss, in dessen Zusammenhang der Begriff \enquote{Künstliche Intelligenz} auch meistens verwendet wird?
Aufgrund dieser Undefiniertheit wird im Folgenden, sofern möglich, auf diesen Begriff verzichtet.

Obwohl die Theorie schon etwas länger existiert, erfolgte ein großer Vorsprung in der Entwicklung des maschinellen Lernens erst in den letzten Jahren. Auch wenn es zuerst nicht so scheint, kommt heute jeder täglich damit in Berührung, beispielsweise
\begin{itemize}
\item im Verkehr, durch möglichst effizient gesteuerte Ampelphasen oder nahezu selbstfahrende Autos sowie Assistenzsysteme wie Spurhalteassistenten, Einparkhilfen oder Ähnliches,
\item im Internet, wo jedem im Sekundentakt neue Inhalte basierend auf persönlichen Präferenzen vorgeschlagen werden,
\item in der Medizin, wo Bilderkennung bei der Auswertung bildgebender Verfahren hilft,
\item in der Industrie, wo Produktionsabläufe durch maschinelles Lernen optimiert wurden
\end{itemize}
und natürlich in vielen weiteren aufwendigeren Prozessen.

Im Folgenden soll es darum gehen, wie ein neuronales Netz funktioniert und wie man es mit maschinellem Lernen verwenden kann.

\subsection{Aufbau neuronaler Netze \cite{NeuronaleNetzeImKlartext}}\label{sec:BasicStructure}
Künstliche neuronale Netze sind sehr stark an natürliche neuronale Netze angelehnt (zum Beispiel an das menschliche Gehirn), weshalb es sinnvoll ist, zuerst diese zu betrachten.

Sogenannte \textit{Neuronen}\index{Neuron} (Nervenzellen) sind durch \textit{Synapsen}\index{Synapse} miteinander verbunden, welche für den Elektronenfluss zwischen jeweils zwei Neuronen mithilfe eines \textit{Synapsengewichts}\index{Synapsengewicht} verantwortlich sind. Mit diesem lässt sich die Anfälligkeit des nachgehenden Neurons auf das Signal des  vorhergehenden Neurons regulieren. \cite{Synapsengewicht}

Es ergibt sich somit das folgende Bild:
\begin{figure}[!h]
\centering
\begin{tikzpicture}[thick, main/.style={draw, circle, inner sep=0pt, minimum width=25pt}]
\node (a1) at (1, 2) {\dots};
\node (a2) at (0, 0) {\dots};
\node (a3) at (1, -2) {\dots};

\node (b1) at (5, 2) {\dots};
\node[main, fill=blue!25] (b2) at (3, 0) {$n_{0, 0}$};
\node (b3) at (5, -2) {\dots};

\node (w1) at (5, 0) {$w_{0, 0, 0}$};

\node[main, fill=blue!25] (c2) at (7, 0) {$n_{1, 0}$};
\node (d2) at (9, 0) {\dots};

\draw[-] (a1) -- (b2);
\draw[-] (a2) -- (b2);
\draw[-] (a3) -- (b2);

\draw[-] (b1) -- (c2);
\draw[-] (b2) -- (w1) -- (c2);
\draw[-] (b3) -- (c2);

\draw[-] (c2) -- (d2);
\end{tikzpicture}
\caption{Synapse zwischen zwei Neuronen}
\label{fig:Neuronenverbindung}
\end{figure}

Es sei jedoch angemerkt, dass ein Neuron beliebig viele vorausgehende oder nachgehende Neuronen haben kann, die in Abbildung \ref{fig:Neuronenverbindung} der Übersicht halber nur durch \enquote{$\cdots$} gekennzeichnet sind. Als grobe Größenordnung sei die Anzahl der Neuronen eines ausgewachsenen, menschlichen Gehirns genannt, welche sich je nach Literatur auf 80 bis 100 Milliarden beläuft.

Eine wichtige Grundlage, um aus dem natürlichen neuronalen Netz ein Künstliches abzuleiten, ist das Betrachten von Ausgaben von Neuronen und von Synapsengewichten als Zahlen. Das ermöglicht die Anwendung von Formeln zur mathematischen Beschreibung.

\begin{figure}[!h]
\centering
\begin{tikzpicture}[thick, main/.style={draw, circle, inner sep=0pt, minimum width=25pt}]
\node[main, fill=red!25] (i1) at (0, 0.75) {};
\node[main, fill=red!25] (i2) at (0, 2.25) {};  
\node[main, fill=red!25] (i3) at (0, 3.75) {};
\node[main, fill=red!25] (i4) at (0, 5.25) {};

\node[main, fill=blue!25] (h11) at (3, 0) {};  
\node[main, fill=blue!25] (h12) at (3, 1.5) {};
\node[main, fill=blue!25] (h13) at (3, 3) {};
\node[main, fill=blue!25] (h14) at (3, 4.5) {};
\node[main, fill=blue!25] (h15) at (3, 6) {};

\node[main, fill=blue!25] (h21) at (6, 0) {};  
\node[main, fill=blue!25] (h22) at (6, 1.5) {};
\node[main, fill=blue!25] (h23) at (6, 3) {};
\node[main, fill=blue!25] (h24) at (6, 4.5) {};
\node[main, fill=blue!25] (h25) at (6, 6) {};

\node[main, fill=green!35] (o1) at (9, 1.5) {};
\node[main, fill=green!35] (o2) at (9, 3) {};
\node[main, fill=green!35] (o3) at (9, 4.5) {};

\draw[-] (i1) -- (h11);\draw[-] (i1) -- (h12);\draw[-] (i1) -- (h13);\draw[-] (i1) -- (h14);\draw[-] (i1) -- (h15);

\draw[-] (i2) -- (h11);\draw[-] (i2) -- (h12);\draw[-] (i2) -- (h13);\draw[-] (i2) -- (h14);\draw[-] (i2) -- (h15);

\draw[-] (i3) -- (h11);\draw[-] (i3) -- (h12);\draw[-] (i3) -- (h13);\draw[-] (i3) -- (h14);\draw[-] (i3) -- (h15);

\draw[-] (i4) -- (h11);\draw[-] (i4) -- (h12);\draw[-] (i4) -- (h13);\draw[-] (i4) -- (h14);\draw[-] (i4) -- (h15);

\draw[-] (h11) -- (h21);\draw[-] (h11) -- (h22);\draw[-] (h11) -- (h23);\draw[-] (h11) -- (h24);\draw[-] (h11) -- (h25);

\draw[-] (h12) -- (h21);\draw[-] (h12) -- (h22);\draw[-] (h12) -- (h23);\draw[-] (h12) -- (h24);\draw[-] (h12) -- (h25);

\draw[-] (h13) -- (h21);\draw[-] (h13) -- (h22);\draw[-] (h13) -- (h23);\draw[-] (h13) -- (h24);\draw[-] (h13) -- (h25);

\draw[-] (h14) -- (h21);\draw[-] (h14) -- (h22);\draw[-] (h14) -- (h23);\draw[-] (h14) -- (h24);\draw[-] (h14) -- (h25);

\draw[-] (h15) -- (h21);\draw[-] (h15) -- (h22);\draw[-] (h15) -- (h23);\draw[-] (h15) -- (h24);\draw[-] (h15) -- (h25);

\draw[-] (o1) -- (h21);\draw[-] (o1) -- (h22);\draw[-] (o1) -- (h23);\draw[-] (o1) -- (h24);\draw[-] (o1) -- (h25);

\draw[-] (o2) -- (h21);\draw[-] (o2) -- (h22);\draw[-] (o2) -- (h23);\draw[-] (o2) -- (h24);\draw[-] (o2) -- (h25);

\draw[-] (o3) -- (h21);\draw[-] (o3) -- (h22);\draw[-] (o3) -- (h23);\draw[-] (o3) -- (h24);\draw[-] (o3) -- (h25);
\end{tikzpicture}
\caption{Aufbau eines einfachen neuronalen Netzes}
\label{fig:Netzaufbau}
\end{figure}

Ebenso wichtig ist die Einteilung aller Neuronen des Netzes in unterschiedliche Schichten, die teilweise sogar unterschiedliche Aufgaben übernehmen müssen. Als Veranschaulichung dafür dient Abbildung \ref{fig:Netzaufbau}, die den Aufbau eines einfachen neuronalen Netzes darstellt. 

Die erste Schicht ist die sogenannte \enquote{Eingabeschicht}\index{Eingabeschicht}\index{Input Layer}, dessen Neuronen (rot) vergleichbar sind mit Sinneszellen. Hier werden Daten gesammelt, mit denen eine Ausgabe generiert werden soll. Es folgen beliebig viele \enquote{versteckte Schichten}\index{Versteckte Schicht}\index{Hidden Layer}. Diese erfüllen den Zweck, dass das Netz auch kompliziertere Dinge lernen kann, da die Gesamtheit der Gewichte ohne versteckte Schicht nur eine linear separierbare Funktion darstellen könnte. Abschließend folgt eine \enquote{Ausgabeschicht}\index{Ausgabeschicht}\index{Output Layer}, welche beispielsweise Entscheidungen des Netzes ausgibt, welche dann in einem anderen Teil des Programms verarbeitet werden. In diesem Fall sind alle Neuronen einer Schicht mit allen Neuronen der nächsten Schicht verbunden. Wie jedoch in Kapitel 2 noch thematisiert wird, existieren auch weitere Strukturen für den Aufbau eines neuronalen Netzes.

Diese Grundlagen ermöglichen beispielsweise eine Berechnung der Ausgabe eines Neurons mit der Formel
\begin{equation}
o_{i, j} = \varphi \left( \sum\limits_{k=0}^{|n_{i-1}| - 1} o_{i-1, k} * w_{i - 1, k, j} \right)
\end{equation}
mit
\begin{itemize}
\item $n_{i, j}$: Neuron in der Schicht $i$ an der Stelle $j$
\item $o_{i, j}$: Ausgabe des Neurons $n_{i, j}$
\item $\varphi$: Differenzierbare Aktivierungsfunktion
\item $|n_i|$: Anzahl der Neuronen in der Schicht $i$
\item $w_{i, k, j}$: Synapsengewicht zwischen den Neuronen $n_{i, k}$ und $n_{i+1, j}$
\end{itemize}

Wörtlich bedeutet das, dass zuerst die Netzeingabe eines Neurons durch Addieren aller Produkte einer Ausgabe eines vorherigen Neurones mit dem jeweiligen Gewicht zwischen den beiden Neuronen berechnet wird. Die Ausgabe des Neurons lässt sich nun mit der \textit{Aktivierungsfunktion}\index{Aktivierungsfunktion} in Abhängigkeit dieser Summe berechnen. Eine Aktivierungsfunktion wird benötigt, damit ein neuronales Netz auch nicht-lineare Eigenschaften erlernen kann.

\subsection{Drei Arten des maschinellen Lernens \cite{PythonMachineLearningChapter1}}\label{sec:MachineLearningTypes}\index{Maschinelles Lernen}
Damit ein neuronales Netz lernt, müssen seine Gewichte angepasst werden. Dieser Vorgang wird auch Training genannt. Das kann auf drei unterschiedliche Arten erfolgen.

\subsubsection{Überwachtes Lernen}\label{sec:SupervisedLearning}\index{Überwachtes Lernen}\index{Maschinelles Lernen}
Das überwachte Lernen ist die wohl am häufigsten verwendete Methode, ein neuronales Netz zu trainieren. Es zielt darauf ab, auch zu bislang unbekannten Eingaben eine passende Ausgabe zu generieren, meistens geht es darum, die Eingaben in Gruppen bestimmter Eigenschaften einzuteilen. 

Während des Trainingsvorgangs wird mithilfe eines Trainingsdatensatzes (einige Eingaben mit zugehörigen erwarteten Ausgaben) angelernt, welche Muster in den Eingabedaten zu bestimmten Ausgaben gehören. Erhält das Netz nach abgeschlossenem Training eine Eingabe, ist es in der Lage, ein Muster darin zu erkennen und anhand dessen eine passende Ausgabe zu generieren.

\begin{figure}[!h]
\centering
\begin{tikzpicture}
\draw[->] (0, 0) -- (0, 5);
\draw[->] (0, 0) -- (5, 0);

\node at (2.5, -.25) {$x$};
\node at (-.25, 2.5) {$y$};

\foreach \i in {1, ..., 15} {
	\node[red!50] at (3.75 + 1.25*rand, 3.75 + 1.25*rand) {•};
	\node[blue!50] at (1.15 + rand, 2.5 + 2.25*rand) {•};
	\node[green!50] at (3.75 + 1.25*rand, 1.25 + rand) {•};
}

\draw[dotted] (2.25, 0) -- (2.25, 5);
\draw[dotted] (2.25, 2.45) -- (5, 2.45);
\end{tikzpicture}
\caption{Klassifizierung von Daten}
\label{fig:SupervisedLearning}
\end{figure}

In Abbildung \ref{fig:SupervisedLearning} sind in einem Diagramm mehrere Punkte unterschiedlicher Farben eingetragen, die jeweils einem $x$- und $y$-Wert zugeordnet sind. Jeder Punkt entspricht dabei einer Eingabe, alle Eingaben derselben Farbe gehören der gleichen Klasse an. Während des Trainings lernt das Netz beispielsweise, dass eine Eingabe mit hohem $x$- und niedrigem $y$-Wert in die grüne Klasse einteilen soll.

\subsubsection{Unüberwachtes Lernen}\label{sec:UnsupervisedLearning}\index{Unüberwachtes Lernen}\index{Maschinelles Lernen}
Das Ziel des unüberwachten Lernens ist es, innerhalb einer Menge von Eingaben Gruppen anhand ähnlicher Strukturen zu finden. Dafür wird keine Bearbeitung oder Sortierung der Daten benötigt.

Daher ist diese Lernart besonders interessant für die Clusteranalyse, welche dasselbe Ziel anstrebt. Sie spielt besonders im Internet eine Rolle, wo Nutzer unterschiedlicher Zielgruppen unterschiedliche Inhalte, Produktvorschläge oder Werbungen angezeigt bekommen sollen.

\begin{figure}[!h]
\centering
\begin{tikzpicture}
\draw[->] (0, 0) -- (0, 5);
\draw[->] (0, 0) -- (5, 0);

\foreach \i in {1, ..., 15} {
	\node[red!50] at (3.75 + .9*rand, 3.75 + .9*rand) {•};
	\node[blue!50] at (1.5 + .9*rand, 1.5 + .9*rand) {•};
	\node[green!50] at (4 + .6*rand, 1 + .6*rand) {•};
}

\draw[dotted] (3.75, 3.75) circle (1.3);
\draw[dotted] (1.5, 1.5) circle (1.3);
\draw[dotted] (4, 1) circle (1);
\end{tikzpicture}
\caption{Gruppierung von Daten}
\label{fig:UnsupervisedLearning}
\end{figure}

In Abbildung \ref{fig:UnsupervisedLearning} sind in einem Diagramm mehrere Punkte unterschiedlicher Farben eingetragen, die jeweils einem $x$- und $y$-Wert zugeordnet sind. Jeder Punkt entspricht dabei einer Eingabe. Anhand der Darstellung ist ersichtlich, dass die $x$- und $y$-Werte von Eingaben gleicher Farbe ähnlich sind, im Vergleich zu den Werten anderer Farben. Diese Ähnlichkeiten gilt es während des Lernvorgangs zu erkennen, sodass auch neu hinzukommende Daten einer der Gruppen zugeordnet werden könnte.

\subsubsection{Bestärktes Lernen}\label{sec:ReinforcementLearning}\index{Bestärktes Lernen}\index{Maschinelles Lernen}
Bestärktes Lernen dient dazu, den Entscheidungsprozess eines neuronales Netzes bezüglich einer bestimmten Tätigkeit zu trainieren.

Dabei wird nach dem Belohnungs-Prinzip gearbeitet: Unterschiedliche Ausgaben erhalten verschiedene Bewertungen, eine Zahl, die einen Vergleich zwischen Gut und Schlecht ermöglichen soll. Eine \enquote{gute} Ausgabe wird belohnt, was darin resultiert, dass die jeweilige Entscheidung verstärkt wird. Entschied sich das Netz falsch, wird es nicht belohnt (oder sogar bestraft) und die Entscheidung wird geschwächt.
Während des Lernvorgangs wird stets versucht, die Bewertung zu maximieren, um immer die bestmögliche Ausgabe zu erreichen.

Die Bewertungen sind hierbei eine Art Feedback für das Netz, weshalb man auch von einer Art des überwachten Lernens sprechen kann.

\subsection{Umgang mit neuronalen Netzen \cite{PythonMachineLearningChapter1}}\label{sec:HandlingNetworks}
Vor der Implementation maschinellen Lernens in einem Programm muss ein neuronales Netz entwickelt werden, das die gewünschte Aufgabe zuverlässig erledigen kann. Für die einzelnen Lernarten existieren standardisierte Abläufe, die von Netz zu Netz nahezu gleich sind. Im Folgenden wird der des überwachten Lernens vorgestellt.

\subsubsection{Vorbereiten eines Trainingsdatensatzes}\label{sec:TrainingData}
Zuerst müssen Daten gesammelt und zu einem \textit{Trainingsdatensatz}\index{Trainingsdatensatz} zusammengefügt werden.
Bei allen Daten handelt es sich um mögliche Eingaben für das Netz. Sollen also beispielsweise Bilder von unterschiedlichen Objekten unterschieden werden, sind die Daten ebenfalls Bilder, auf denen die zu klassifizierenden Objekte enthalten sind.

Neben dem einfachen Zusammenstellen des Datensatzes kann es jedoch auch vorkommen, dass Daten zuerst bearbeitet werden müssen, sodass einzelne Details auffälliger sind. Das kann geschehen, indem beispielsweise ein Bild auf die relevanten Pixel reduziert wird. Dadurch lernt das Netz nicht nur besser, sondern auch schneller und mit einer geringeren Datenmenge als würden Daten nicht optimiert werden.

Sämtliche Anpassungen der Daten müssen einheitlich und auch bei der Anwendung des Netzes mit unbekannten Daten erfolgen.

Außerdem ist es für die bevorstehende Auswertung (\ref{sec:Evaluation}) wichtig, dass ebenfalls ein \textit{Testdatensatz}\index{Testdatensatz} erstellt wird. Sein Aufbau ist gleich wie der des Trainingsdatensatzes, es sind lediglich andere Daten enthalten. 

\subsubsection{Trainieren}\label{sec:Training}\index{Training}
Mit dem fertigen Trainingsdatensatz\index{Trainingsdatensatz} kann das neuronale Netz \textit{trainiert} werden. Dafür existieren unterschiedliche Trainingsalgorithmen, die sich auch zwischen besonderen Aufbauten neuronaler Netze und deren spezifischen Aufgaben unterscheiden können. 

Je nach Aufgabe oder spezifischen Struktur des Netzes können die Algorithmen unterschiedlich gut abschließen. Daher ist es lohnenswert, das Training nicht nur auf einen der Algorithmen zu beschränken, sondern mehrere mit Bezug auf die durchzuführende Aufgabe zu testen.

\subsubsection{Auswertung und Anwendung}\label{sec:Evaluation}\index{Auswertung}
Nachdem das Training abgeschlossen wurde, ist es interessant zu wissen, mit welcher Genauigkeit oder Zuverlässigkeit eine Aufgabe ausgeführt wird. Dafür kommt der zuvor erstellte Testdatensatz\index{Testdatensatz} (\ref{sec:TrainingData}) in Einsatz, mit dem die Anzahl der falschen bzw. unerwünschten Ausgaben ermittelt wird und der somit eine Einschätzung des Netzes möglich macht.

Für diese Auswertung ist es wichtig, dass der Testdatensatz nicht dieselben Daten enthält wie der Trainingsdatensatz, was simulieren soll, wie sich das Netz mit bislang unbekannten Daten verhält. Würde man das neuronale Netz mit den Trainingsdaten evaluiert werden, könnte es im schlechtesten Fall vorkommen, dass das Netz jedes kleinste Detail einer bekannten Eingabe anlernt, zu anderen Daten allerdings nahezu zufällige Ausgaben erzeugt. Eine solche Entwicklung wird auch \textit{Overfitting}\index{Overfitting} genannt. Dabei muss es sich jedoch nicht zwangsläufig um den hier beschriebenen Fall handeln, Overfitting kann auch eine Erscheinung sein, welche dann auftritt, wenn ein Training besonders viele Iterationen in Anspruch nimmt.

Wenn die Aufgabe zufriedenstellend abgeschlossen wird, können die Gewichte und die Konfiguration des Netzes in Dateien abgespeichert und in einem Anwendungsprogramm importiert. Das ermöglicht eine Rekonstruktion des neuronalen Netzes ohne großen Zeitaufwand und ohne erneut ein Training durchführen zu müssen.

\section{Deep Convolutional Neural Networks \cite{PythonMachineLearningChapter15}}\label{sec:DCNN}\index{Neuronales Netz}\index{Convolutional Neural Network}
Deep \textit{Convolutional Neural Networks} (CNN) - im Deutschen \textit{Faltungsnetze}\index{Faltungsnetz} - sind besondere Formen der neuronalen Netze\index{Neuronales Netz}, die besonders in der Bilderkennung und -Klassifikation\index{Bildklassifikation} sehr häufig verwendet werden. Grund dafür ist, dass sie viel schneller und besser trainiert werden können als herkömmliche neuronale Netze. Während diese eine Genauigkeit von über 90\% erst spät erreichen, lernen CNN's innerhalb weniger Epochen ein Bild mit einer Wahrscheinlichkeit von über 95\% korrekt zu klassifizieren.

Das ist auf deren Aufbau und Lernweise zurückzuführen, welche der des Menschen noch mehr ähnelt als die herkömmlicher neuronaler Netze.

\subsection{Convolutional Layer}\label{sec:ConvolutionalLayer}\index{Convolutional Layer}
Verwendet man ein übliches neuronales Netz für die Bildklassifikation, ist die Relevanz zweier nebeneinanderliegender Pixel genauso hoch wie die von weit entfernten Pixeln. Das folgt daraus, dass die Ausgabe jedes Neurons an jedes Neuron der Folgeschicht propagiert wird.

In einem Convolutional Layer ist das anders: Mithilfe eines \textit{Kernels}\index{Kernel} werden aus nebeneinanderliegenden Pixeln Eigenschaften erkannt. Erkennbare Eigenschaften beschränken sich in den höheren Schichten auf einfache Formen wie zum Beispiel Kanten, je tiefer sich eine Schicht jedoch im Netz befindet, kann diese immer komplexere Objekte anhand von Konturen unterscheiden.

Um das zu erreichen, wird die \textit{Convolution}\index{Convolution}, oder eine Vereinfachung, die häufiger in Machine-Learning-Frameworks implementiert ist, die\textit{ Cross Correlation}\index{Cross Correlation}, angewandt.

\subsubsection{Eindimensionale Cross Correlation}\label{sec:CrossCorrelation1D}\index{Cross Correaltion}
Als \textit{Cross Correlation} wird im Folgenden eine Operation mit einem Eingabevektor $x$ und einem \textit{Kernel}\index{Kernel} $w$ betrachtet, aus dem ein Ausgabevektor $y$ berechnet werden soll. Die Cross Correlation ist eine Vereinfachung der \textit{Convolution}\index{Convolution}, wobei der Unterschied im Wesentlichen darin besteht, dass der Kernel bei der Convolution zuerst gespiegelt werden muss.

Mit der Bedingung
\[
|x| \geq |w| \qquad |x|, \: |w| > 0
\]
kann die \textit{valide} Cross Correlation\index{Cross Correlation} im eindimensionalen Raum mathematisch durch die Formel
\begin{equation}
y = x \odot w \quad \rightarrow \quad y_i = \sum\limits_{k=0}^{|w| - 1} x_{i+k} * w_{k}
\end{equation}
beschrieben werden. Im Folgenden entspricht das Symbol \enquote{$\odot$} der Cross-Correlation-Operation. In Worten bedeutet das, dass der Kernel\index{Kernel} $w$ an den Eingaben $x$ angelegt wird. Addiert man das Produkt der einzelnen Werte $x_i$ und $w_i$, ermittelt man $y_i$. Um $y_{i+1}$ zu berechnen, muss der Kernel um eine Einheit verschoben werden. Ein Sinnbild ist in Abbildung \ref{fig:CrossCorrelationNoPadding} dargestellt.

\begin{figure}[!h]
\centering
\begin{tikzpicture}[thick, main/.style={draw, rectangle, inner sep=0pt, minimum width=1cm, minimum height=1cm}]
\node at (-1.5, .25) {$x$};
\node[text=blue!50] at (-1, -.25) {$w$};
\node at (-.5, -2.5) {$y$};

\node[main] at (0, 0) {};
\node[main] at (1, 0) {};
\node[main] at (2, 0) {};
\node[main] at (3, 0) {};
\node[main] at (4, 0) {};

\node[main, draw=blue!35, line width=.75mm] at (.25, -.25) {};
\node[main, draw=blue!35, line width=.75mm] at (1.25, -.25) {};
\node[main, draw=blue!35, line width=.75mm] at (2.25, -.25) {};

\node[main, fill=blue!25] at (1, -2.5) {};
\node[main] at (2, -2.5) {};
\node[main] at (3, -2.5) {};

\draw[dashed, draw=blue!25, line width=.5mm] (-.25, -.75) -- (.5, -3);
\draw[dashed, draw=blue!25, line width=.5mm] (-.25, .25) -- (.5, -2);
\draw[dashed, draw=blue!25, line width=.5mm] (2.75, -.75) -- (1.5, -3);
\draw[dashed, draw=blue!25, line width=.5mm] (2.75, .25) -- (1.5, -2);
\end{tikzpicture}
$\qquad$
\begin{tikzpicture}[thick, main/.style={draw, rectangle, inner sep=0pt, minimum width=1cm, minimum height=1cm}]
\node[main] at (0, 0) {};
\node[main] at (1, 0) {};
\node[main] at (2, 0) {};
\node[main] at (3, 0) {};
\node[main] at (4, 0) {};

\node[main, draw=blue!35, line width=.75mm] at (1.25, -.25) {};
\node[main, draw=blue!35, line width=.75mm] at (2.25, -.25) {};
\node[main, draw=blue!35, line width=.75mm] at (3.25, -.25) {};

\node[main] at (1, -2.5) {};
\node[main, fill=blue!25] at (2, -2.5) {};
\node[main] at (3, -2.5) {};

\draw[dashed, draw=blue!25, line width=.5mm] (.75, -.75) -- (1.5, -3);
\draw[dashed, draw=blue!25, line width=.5mm] (.75, .25) -- (1.5, -2);
\draw[dashed, draw=blue!25, line width=.5mm] (3.75, -.75) -- (2.5, -3);
\draw[dashed, draw=blue!25, line width=.5mm] (3.75, .25) -- (2.5, -2);
\end{tikzpicture}
\caption{Cross Correlation im eindimensionalen Raum, ohne Padding}
\label{fig:CrossCorrelationNoPadding}
\end{figure}

Es ist offensichtlich, dass die Länge des Ausgabevektors $y$ unter diesen Bedingungen stets kleiner als die Länge der Eingabe sein wird. Ein solcher Informationsverlust von Pixeln kann jedoch zu Ungenauigkeiten führen. Daher wird ein \textit{Padding}\index{Padding} eingeführt, welches den Eingabevektor $x$ künstlich mit Nullen erweitern soll. Zur Ermittlung des Ausgabevektors $y$ entsteht das in Abbildung \ref{fig:CrossCorrelationWithPadding} dargestellte Schema. Man spricht nun nicht mehr von der validen Cross Correlation, sondern von einer Cross Correlation mit \textit{Same Padding}, bei dem der Ausgabevektor $y$ dieselbe Länge hat wie der Eingabevektor $x$. Darüber hinaus existiert noch das \textit{Full Padding}, bei dem der Eingabevektor $x$ mit noch mehr Nullen erweitert wird. Dadurch wird die Ausgabe nach einem Convolutional Layer größer als die Eingabe, wodurch allerdings eine Vergrößerung von Daten stattfindet. Der damit verbundene Rechenaufwand ist der Grund, weshalb das Full Padding selten Anwendung findet.

\begin{figure}[!h]
\centering
\begin{tikzpicture}[thick, main/.style={draw, rectangle, inner sep=0pt, minimum width=1cm, minimum height=1cm}]
\node at (-2.5, .25) {$x^p$};
\node[text=blue!50] at (-2, -.25) {$w$};
\node at (-1.5, -2.5) {$y$};

\node[main, dotted] at (-1, 0) {$0$};
\node[main] at (0, 0) {};
\node[main] at (1, 0) {};
\node[main] at (2, 0) {};
\node[main] at (3, 0) {};
\node[main] at (4, 0) {};
\node[main, dotted] at (5, 0) {$0$};

\node[main, draw=blue!35, line width=.75mm] at (-.75, -.25) {};
\node[main, draw=blue!35, line width=.75mm] at (.25, -.25) {};
\node[main, draw=blue!35, line width=.75mm] at (1.25, -.25) {};

\node[main, fill=blue!25] at (0, -2.5) {};
\node[main] at (1, -2.5) {};
\node[main] at (2, -2.5) {};
\node[main] at (3, -2.5) {};
\node[main] at (4, -2.5) {};

\draw[dashed, draw=blue!25, line width=.5mm] (-1.25, -.75) -- (-.5, -3);
\draw[dashed, draw=blue!25, line width=.5mm] (-1.25, .25) -- (-.5, -2);
\draw[dashed, draw=blue!25, line width=.5mm] (1.75, -.75) -- (.5, -3);
\draw[dashed, draw=blue!25, line width=.5mm] (1.75, .25) -- (.5, -2);
\end{tikzpicture}
\caption{Cross Correlation im eindimensionalen Raum, mit Padding}
\label{fig:CrossCorrelationWithPadding}
\end{figure}

\subsubsection{Zweidimensionale Cross Correlation}\label{sec:CrossCorrelation2D}\index{Cross Correlation}
Bilder sind allerdings nicht eindimensional, weshalb die zweidimensionale Cross Correlation benötigt wird. 

Unter Definition der Variablen
\begin{itemize}
\item $X^p$: Eingabematrix ($\hat{=}$ Bild, einfarbig, mit Nullen entsprechend des Paddings erweitert)
\item $W$: Kernel-Matrix
\item $Y$: Ausgabematrix (Bild mit angewandtem Filter)
\end{itemize}
kann diese durch die Formel
\begin{equation}
Y = X \odot W \quad \rightarrow \quad Y_{i, j} = \sum\limits_{k=0}^{|W|} \; \sum\limits_{l=0}^{|W_l|} X^p_{i+k, j+l} * W_{k, j}
\end{equation}
beschrieben werden, anhand des Schemas und Abbildung \ref{fig:CrossCorrelation2D} ist sie jedoch einfacher zu verstehen.

\begin{figure}[!h]
\centering
\scalebox{.95}{
\begin{tikzpicture}
\node at (2.5, 1.5) {$X^p$};
\node[text=blue!50] at (.75, 2) {$W$};
\node at (9.5, 1) {$Y$};
\draw[-] (0, 0) -- (5, -1) -- (5, -6) -- (0, -5) -- (0, 0);
\draw[-] (0, -1) -- (5, -2);
\draw[-] (0, -2) -- (5, -3);
\draw[-] (0, -3) -- (5, -4);
\draw[-] (0, -4) -- (5, -5);
\draw[-] (1, -.2) -- (1, -5.2);
\draw[-] (2, -.4) -- (2, -5.4);
\draw[-] (3, -.6) -- (3, -5.6);
\draw[-] (4, -.8) -- (4, -5.8);
\draw[dotted] (-1, 1.2) -- (6, -.2) -- (6, -7.2) -- (-1, -5.8) -- (-1, 1.2);
\draw[dotted] (0, 1) -- (0, -6);
\draw[dotted] (1, .8) -- (1, -6.2);
\draw[dotted] (2, .6) -- (2, -6.4);
\draw[dotted] (3, .4) -- (3, -6.6);
\draw[dotted] (4, .2) -- (4, -6.8);
\draw[dotted] (5, 0) -- (5, -7);
\draw[dotted] (-1, .2) -- (6, -1.2);
\draw[dotted] (-1, -.8) -- (6, -2.2);
\draw[dotted] (-1, -1.8) -- (6, -3.2);
\draw[dotted] (-1, -2.8) -- (6, -4.2);
\draw[dotted] (-1, -3.8) -- (6, -5.2);
\draw[dotted] (-1, -4.8) -- (6, -6.2);
\node at (-.5, .6) {$0$};
\node at (.5, .4) {$0$};
\node at (1.5, .2) {$0$};
\node at (2.5, 0) {$0$};
\node at (3.5, -.2) {$0$};
\node at (4.5, -.4) {$0$};
\node at (5.5, -.6) {$0$};
\node at (5.5, -1.6) {$0$};
\node at (5.5, -2.6) {$0$};
\node at (5.5, -3.6) {$0$};
\node at (5.5, -4.6) {$0$};
\node at (5.5, -5.6) {$0$};
\node at (5.5, -6.6) {$0$};
\node at (4.5, -6.4) {$0$};
\node at (3.5, -6.2) {$0$};
\node at (2.5, -6) {$0$};
\node at (1.5, -5.8) {$0$};
\node at (.5, -5.6) {$0$};
\node at (-.5, -5.4) {$0$};
\node at (-.5, -4.4) {$0$};
\node at (-.5, -3.4) {$0$};
\node at (-.5, -2.4) {$0$};
\node at (-.5, -1.4) {$0$};
\node at (-.5, -.4) {$0$};
\draw[-, draw=blue!35, line width=.75mm] (-.75, .95) -- (2.25, .35) -- (2.25, -2.65) -- (-.75, -2.05) -- (-.75, .95);
\draw[-, draw=blue!35, line width=.75mm] (.25, .75) -- (.25, -2.25);
\draw[-, draw=blue!35, line width=.75mm] (1.25, .55) -- (1.25, -2.45);
\draw[-, draw=blue!35, line width=.75mm] (-.75, -.05) -- (2.25, -.65);
\draw[-, draw=blue!35, line width=.75mm] (-.75, -1.05) -- (2.25, -1.65);
\fill[fill=blue!25] (7, 0) -- (8, -.2) -- (8, -1.2) -- (7, -1);
\draw[-] (7, 0) -- (12, -1) -- (12, -6) -- (7, -5) -- (7, 0);
\draw[-] (7, -1) -- (12, -2);
\draw[-] (7, -2) -- (12, -3);
\draw[-] (7, -3) -- (12, -4);
\draw[-] (7, -4) -- (12, -5);
\draw[-] (8, -.2) -- (8, -5.2);
\draw[-] (9, -.4) -- (9, -5.4);
\draw[-] (10, -.6) -- (10, -5.6);
\draw[-] (11, -.8) -- (11, -5.8);
\draw[dashed, draw=blue!25, line width=.5mm] (-.75, .95) -- (7, 0);
\draw[dashed, draw=blue!25, line width=.5mm] (2.25, .35) -- (8, -.2);
\draw[dashed, draw=blue!25, line width=.5mm] (2.25, -2.65) -- (8, -1.2);
\draw[dashed, draw=blue!25, line width=.5mm] (-.75, -2.05) -- (7, -1);
\end{tikzpicture}
}
\caption{Cross Correlation im zweidimensionalen Raum}
\label{fig:CrossCorrelation2D}
\end{figure}

Auch hier wird die Kernel-Matrix\index{Kernel} $W$ an die Eingabematrix $X^p$ angelegt und verschoben, um die Werte der Ausgabe $Y$ durch Addieren der Produkte zu berechnen. Es ist jedoch zu beachten, dass $W$ in diesem Fall in beide Richtungen verschoben wird, sodass eine zweidimensionale Ausgabe entsteht.

\subsubsection{Praktische Anwendung}\label{sec:PracticalConvolution}
In der Praxis muss ein \textit{Convolutional Layer}\index{Convolutional Layer} mehrere zweidimensionale Eingabematrizen annehmen können, da beispielsweise Bilder nicht (alle) einfarbig sind. Daher werden mehrere Eingabechannel\index{Channel} definiert, für jede Eingabematrix einer. Um beispielsweise ein Farbbild einzugeben, würden 3 Channel benötigt, da ein solches Bild in die Farben rot, grün und blau unterteilt ist.

Auch die Anzahl der Ausgabematrizen soll für jede Schicht variabel, aber konstant sein. Jede Eingabematrix hat dabei einen Einfluss auf jede Ausgabematrix.

Um diesen Einfluss zu steuern wird eine Anpassung der Dimensionen des Kernels benötigt. Diese sind nun die Anzahl der Ausgabematrizen, die Anzahl der Eingabematrizen, die Größe und die Breite der Gewichte, weshalb der Kernel nun als vierdimensionales Array implementiert wird.

Eine Berechnung der Ausgabematrix $Y_i$ des Ausgabechannels $i$ lässt sich nun formal durch
\begin{equation}
Y_i = \sum\limits_{j=0}^{|X| - 1} X_j \odot W_{i, j}
\end{equation}
ausdrücken. 

Im Anschluss an die Berechnung einer Ausgabematrix $Y_i$ muss darauf noch die bereits aus Kapitel 1 bekannte differenzierbare Aktivierungsfunktion\index{Aktivierungsfunktion} angewandt werden. Es entsteht mit 
\[
A_i = \varphi (Y_i)
\]
eine sogenannte \textit{Feature Map}\index{Feature Map}. Diese enthalten in tieferen Schichten immer abstrakter werdende Eigenschaften der zu klassifizierenden Objekte, welche eine viel genauere Erkennung eines Objekts ermöglicht.

\subsection{Subsampling Layer}\label{sec:SubsamplingLayer}\index{Subsampling}\index{Subsampling Layer}
\textit{Subsampling Layers} kommen in neuronalen Netzen vor, um die Menge an Eigenschaften einer Eingabe mittels \textit{Pooling-Operationen}\index{Pooling} zu verringern. Das resultiert in einem deutlich schnelleren Trainingsvorgang mit nur geringerem Leistungsverlust, da nach einem Subsampling Layer deutlich weniger Gewichte angepasst werden müssen.

\begin{figure}[!h]
\centering
\begin{tikzpicture}[thick, main/.style={draw, rectangle, inner sep=0pt, minimum width=.5cm, minimum height=.5cm}]
\node[main, fill=blue!25] at (0, 0) {3};
\node[main, fill=blue!25] at (.5, 0) {1};
\node[main, fill=orange!35] at (1, 0) {5};
\node[main, fill=orange!35] at (1.5, 0) {1};

\node[main, fill=blue!25] at (0, .5) {2};
\node[main, fill=blue!25] at (.5, .5) {6};
\node[main, fill=orange!35] at (1, .5) {2};
\node[main, fill=orange!35] at (1.5, .5) {4};

\node[main, fill=red!25] at (0, 1) {9};
\node[main, fill=red!25] at (.5, 1) {3};
\node[main, fill=green!35] at (1, 1) {8};
\node[main, fill=green!35] at (1.5, 1) {1};

\node[main, fill=red!25] at (0, 1.5) {7};
\node[main, fill=red!25] at (.5, 1.5) {1};
\node[main, fill=green!35] at (1, 1.5) {2};
\node[main, fill=green!35] at (1.5, 1.5) {5};

\draw[->] (2.5, .75) -- (3.5, .75);

\node at (4.75, 2.5) {Max-Pooling};
\node[main, fill=red!25] at (4.5, 1.75) {9};
\node[main, fill=green!25] at (5, 1.75) {8};
\node[main, fill=blue!25] at (4.5, 1.25) {6};
\node[main, fill=orange!25] at (5, 1.25) {5};

\node at (4.75, -1) {Mean-Pooling};
\node[main, fill=red!25] at (4.5, .25) {5};
\node[main, fill=green!25] at (5, .25) {4};
\node[main, fill=blue!25] at (4.5, -.25) {3};
\node[main, fill=orange!25] at (5, -.25) {3};
\end{tikzpicture}
\caption{Max- und Mean-Pooling}
\end{figure}

Eine Eingabe $X$ wird in mehrere kleine Pooling-Matrizen $P$ aufgeteilt. Ab diesem Punkt können zwei unterschiedliche Arten angewandt werden: Bei \textit{Max-Pooling} wird jeweils der größte Wert der Pooling-Matrix in die Ausgabe weitergeleitet, bei \textit{Mean-Pooling} wird der Durchschnitt aller darin enthaltenen Werte ermittelt.

Subsampling Layer selbst haben keine Gewichte sondern beruhen auf simplen mathematischen Berechnungen wie dem Durchschnitt oder einem Größenvergleich.

\subsection{Aufbau von CNN's}\label{sec:CNNArchitecture}\index{Neuronales Netz}\index{Convolutional Neural Network}\index{Faltungsnetz}
\begin{figure}[!h]
\centering
\begin{tikzpicture}[thick, main/.style={draw, circle, inner sep=0pt, minimum width=.25cm}]

\def\lgt{1.5};
\def\xo{0};
\def\yo{0};
\def\dst{.2};
\draw[-] (0+\xo, 0+\yo) -- (0+\xo, \lgt+\yo) -- (\lgt+\xo, \lgt+\yo) -- (\lgt+\xo, 0+\yo) -- (0+\xo, 0+\yo);
\foreach \n in {0, ..., 1} {
\draw[-] (-\dst*\n+\xo, \dst*\n+\dst+\yo) -- (-\dst*\n-\dst+\xo, \dst*\n+\dst+\yo) -- (-\dst*\n-\dst+\xo, \dst*\n+\dst+\lgt+\yo) -- (-\dst*\n-\dst+\lgt+\xo, \dst*\n+\dst+\lgt+\yo) -- (-\dst*\n-\dst+\lgt+\xo, \dst*\n+\lgt+\yo);
}

\def\lgt{1.5};
\def\xo{2.5};
\def\yo{-.15};
\def\dst{.1};
\draw[-] (0+\xo, 0+\yo) -- (0+\xo, \lgt+\yo) -- (\lgt+\xo, \lgt+\yo) -- (\lgt+\xo, 0+\yo) -- (0+\xo, 0+\yo);
\foreach \n in {0, ..., 6} {
\draw[-] (-\dst*\n+\xo, \dst*\n+\dst+\yo) -- (-\dst*\n-\dst+\xo, \dst*\n+\dst+\yo) -- (-\dst*\n-\dst+\xo, \dst*\n+\dst+\lgt+\yo) -- (-\dst*\n-\dst+\lgt+\xo, \dst*\n+\dst+\lgt+\yo) -- (-\dst*\n-\dst+\lgt+\xo, \dst*\n+\lgt+\yo);
}

\def\lgt{1};
\def\xo{5};
\def\yo{.15};
\def\dst{.1};
\draw[-] (0+\xo, 0+\yo) -- (0+\xo, \lgt+\yo) -- (\lgt+\xo, \lgt+\yo) -- (\lgt+\xo, 0+\yo) -- (0+\xo, 0+\yo);
\foreach \n in {0, ..., 6} {
\draw[-] (-\dst*\n+\xo, \dst*\n+\dst+\yo) -- (-\dst*\n-\dst+\xo, \dst*\n+\dst+\yo) -- (-\dst*\n-\dst+\xo, \dst*\n+\dst+\lgt+\yo) -- (-\dst*\n-\dst+\lgt+\xo, \dst*\n+\dst+\lgt+\yo) -- (-\dst*\n-\dst+\lgt+\xo, \dst*\n+\lgt+\yo);
}

\def\lgt{1};
\def\xo{7.5};
\def\yo{-.05};
\def\dst{.075};
\draw[-] (0+\xo, 0+\yo) -- (0+\xo, \lgt+\yo) -- (\lgt+\xo, \lgt+\yo) -- (\lgt+\xo, 0+\yo) -- (0+\xo, 0+\yo);
\foreach \n in {0, ..., 14} {
\draw[-] (-\dst*\n+\xo, \dst*\n+\dst+\yo) -- (-\dst*\n-\dst+\xo, \dst*\n+\dst+\yo) -- (-\dst*\n-\dst+\xo, \dst*\n+\dst+\lgt+\yo) -- (-\dst*\n-\dst+\lgt+\xo, \dst*\n+\dst+\lgt+\yo) -- (-\dst*\n-\dst+\lgt+\xo, \dst*\n+\lgt+\yo);
}

\def\lgt{.65};
\def\xo{9.5};
\def\yo{.3};
\def\dst{.05};
\draw[-] (0+\xo, 0+\yo) -- (0+\xo, \lgt+\yo) -- (\lgt+\xo, \lgt+\yo) -- (\lgt+\xo, 0+\yo) -- (0+\xo, 0+\yo);
\foreach \n in {0, ..., 14} {
\draw[-] (-\dst*\n+\xo, \dst*\n+\dst+\yo) -- (-\dst*\n-\dst+\xo, \dst*\n+\dst+\yo) -- (-\dst*\n-\dst+\xo, \dst*\n+\dst+\lgt+\yo) -- (-\dst*\n-\dst+\lgt+\xo, \dst*\n+\dst+\lgt+\yo) -- (-\dst*\n-\dst+\lgt+\xo, \dst*\n+\lgt+\yo);
}

\node[main] (n00) at (11, 0) {};
\node at (11, .7) {$\vdots$};
\node[main] (n01) at (11, 1.2) {};
\node[main] (n02) at (11, 1.6) {};
\node[main] (n03) at (11, 2) {};

\node[main] (n10) at (12, 0) {};
\node at (12, .7) {$\vdots$};
\node[main] (n11) at (12, 1.2) {};
\node[main] (n12) at (12, 1.6) {};
\node[main] (n13) at (12, 2) {};

\node[main] (n20) at (13, .2) {};
\node at (13, .9) {$\vdots$};
\node[main] (n21) at (13, 1.4) {};
\node[main] (n22) at (13, 1.8) {};

\draw[-] (n00) -- (n10);
\draw[-] (n00) -- (n11);
\draw[-] (n00) -- (n12);
\draw[-] (n00) -- (n13);
\draw[-] (n01) -- (n10);
\draw[-] (n01) -- (n11);
\draw[-] (n01) -- (n12);
\draw[-] (n01) -- (n13);
\draw[-] (n02) -- (n10);
\draw[-] (n02) -- (n11);
\draw[-] (n02) -- (n12);
\draw[-] (n02) -- (n13);
\draw[-] (n03) -- (n10);
\draw[-] (n03) -- (n11);
\draw[-] (n03) -- (n12);
\draw[-] (n03) -- (n13);
\draw[-] (n10) -- (n20);
\draw[-] (n10) -- (n21);
\draw[-] (n10) -- (n22);
\draw[-] (n11) -- (n20);
\draw[-] (n11) -- (n21);
\draw[-] (n11) -- (n22);
\draw[-] (n12) -- (n20);
\draw[-] (n12) -- (n21);
\draw[-] (n12) -- (n22);
\draw[-] (n13) -- (n20);
\draw[-] (n13) -- (n21);
\draw[-] (n13) -- (n22);

\path[->, thick] (0.25, 2.1) edge[bend left] node[above, align=center] {\textbf{Convolution}\\Kernel-Größe:\\$8 \times 3 \times x \times y$} (2.5, 2.2);
\path[->, thick] (3.5, -.3) edge[bend right] node[below, align=center] {\textbf{Subsampling}\\Pooling-Größe\\$2 \times 2$} (5.5, 0);
\path[->, thick] (4.8, 2) edge[bend left] node[above, align=center] {\textbf{Convolution}\\Kernel-Größe:\\$16 \times 8 \times x' \times y'$} (6.7, 2.2);
\path[->, thick] (8, -.2) edge[bend right] node[below, align=center] {\textbf{Subsampling}\\Pooling-Größe\\$2 \times 2$} (9.8, .1);
\path[->, thick] (9.1, 1.9) edge[bend left] node[above, align=center] {\textbf{Flattening}} (10.8, 2.2);
\end{tikzpicture}
\caption{Exemplarischer Aufbau eines Convolutional Neural Networks}
\label{fig:CNNArchitecture}
\end{figure}
Convolutional Neural Networks sind sowohl aus diesen Convolutional und Subsampling Layers\index{Convolutional Layer}\index{Subsampling Layer}, als auch aus den bereits bekannten vollständig verbundenen Schichten\index{Versteckte Schicht}\index{Hidden Layer}\index{Ausgabeschicht}\index{Output Layer} aufgebaut.

Der im Folgenden beschriebene Aufbau ist in Abbildung \ref{fig:CNNArchitecture} dargestellt.

Noch außerhalb des Netzes wird ein farbiges Bild in die drei Farbkomponenten rot, grün und blau aufgeteilt, sodass für jede eine einzelne Matrix entsteht mit Werten, die beschreiben, wie hoch der Anteil der jeweiligen Farbe an dem entsprechenden Pixel ist.

Die entstandenen Matrizen entsprechen der Eingabe des ersten Convolutional Layer\index{Convolutional Layer}. Diese Schicht führt Convolutions bzw. Cross Correlations\index{Convolution}\index{Cross Correlation} mit einem Kernel der Größe $3 \times 3$ oder $5 \times 5$\index{Kernel} durch, wobei die Anzahl der Ausgabechannel\index{Channel} meist zwischen 8 und 32 liegt. Die optimale Wahl dieser Anzahl oder der Kernel-Größe ist abhängig von der auszuführenden Aufgabe und ihrer Komplexität sowie der Größe der Bilder. Am besten lassen sich die Werte in Tests ermitteln.

Anschließend erfolgt ein Subsampling\index{Subsampling}\index{Subsampling Layer} der Matrizen mit der Pooling-Größe $2 \times 2$, handelt es sich jedoch um größere Bilder mit größeren Details können diese aber auch mit der Pooling-Größe $4 \times 4$ verkleinert werden. Im Normalfall wird die Max-Pooling-Strategie\index{Pooling} verwendet, auf einen Vergleich mit Mean-Pooling sollte jedoch nicht ohne Weiteres verzichtet werden.

Je nach Komplexität der zu erledigenden Aufgabe und der nach dem Pooling verbleibenden Größe der Feature Map\index{Feature Map} folgen weitere Convolutions\index{Convolution}\index{Cross Correlation}\index{Convolutional Layer} mit jeweils einem Subsampling Layer\index{Subsampling Layer}. Auch hier sind die einzelnen Werte der Schichten mit Feingefühl zu ermitteln und sollten zu Testzwecken verändert werden.

Nach der letzten Subsampling-Schicht\index{Subsampling Layer} erfolgt ein Abflachen oder \textit{Flattening}\index{Flattening} aller Matrizen, was in der Regel in einer eigenen Schicht\index{Flattening Layer} realisiert wird. Dieses Abflachen geschieht durch Aneinanderreihen der Zeilen aller Matrizen, wodurch letztendlich ein eindimensionaler Vektor entsteht.

Dieser Vektor kann durch ein herkömmliches, vollständig verbundenes neuronales Netz\index{Neuronales Netz} propagiert werden. Da die Eingabe sehr abstrakte Eigenschaften beschreibt, die unmittelbar mit der zuzuordnenden Klasse in Verbindung stehen, wird hier in den meisten Fällen nicht mehr als eine versteckte Schicht\index{Versteckte Schicht}\index{Hidden Layer} benötigt.

\subsection{Ziffernerkennung mit einem Convolutional Neural Network}\label{sec:Application}
\subsubsection{Der MNIST-Datensatz}\label{sec:MNISTDataset}\index{MNIST-Datensatz}
Beim MNIST-Datensatz handelt es sich um einen einfachen Bilderkennungs-Datensatz, der wegen seiner Simplizität und Bekanntheit gerne als Einstiegs- oder Testbeispiel verwendet wird.

Er umfasst 70.000 Graustufen-Bilder der Größe $28 \times 28$ Pixel, wobei jedes Bild eine handgeschriebene Ziffer von 0 bis 9 enthält. Das Ziel des Netzes soll es sein, die Bilder eindeutig einer der Ziffern zuzuordnen.

\subsubsection{Das TensorFlow-Framework}\label{sec:TensorFlow}\index{TensorFlow}
TensorFlow ist ein Open-Source Machine-Learning-Framework von Google, das hauptsächlich auf die Programmiersprachen Python und C++ ausgelegt ist, jedoch auch mit vielen weiteren kompatibel ist. Mit der Version 2.0 werden mittlerweile nahezu alle Architekturen neuronaler Netze unterstützt, wodurch es im Bereich des Data Science sehr beliebt wurde.

Mit TensorFlow hat man die Möglichkeit, sein eigenes neuronales Netz mit selbst gewählten Parametern Schicht für Schicht zusammenzustellen. Das ermöglicht jedem, selbst einen idealen Aufbau zu finden, der die Aufgabe am Besten erfüllt. Das Training, und somit der schwierigere Teil, wird allerdings vom Framework abgenommen.

\subsubsection{Ziffernerkennung}
Im Folgenden soll TensorFlow dazu verwendet werden, die Daten des MNIST-Datensatzes mit einem CNN\index{Convolutional Neural Network}\index{Faltungsnetz} zu klassifizieren. Anschließend erfolgt ein Vergleich der erreichten Ergebnisse mit denen eines vollständig verbundenen neuronalen Netzes.

Sämtlicher Code kann unter
\begin{center}
\footnotesize\url{https://colab.research.google.com/drive/1n-t1O-3lq-VovD4DCZmhpc9q8Ht4n4At}
\end{center} 
abgerufen werden. Alternativ befindet sich am Ende des Kapitels ein QR-Code zum Scannen.

\subsubsection*{Laden des MNIST-Datensatzes in TensorFlow}
Mit dem folgenden Code wird das TensorFlow-Framework eingebunden und der MNIST-Datensatz heruntergeladen. Im Anschluss werden die Farbanteile von einem ursprünglichen Bereich von 0 bis 255 auf 0 bis 1 skaliert und eine Daten in Trainings- und Testdatensatz eingeteilt, jeweils mit einer Batch-Größe von 64 Daten. Das bedeutet, dass mit einer Trainings-Iteration 64 Daten trainiert werden.
\begin{lstlisting}[language=Python]
import tensorflow as tf
import tensorflow_datasets as tfds

## Build Datasets
mnist_builder = tfds.builder('mnist')
mnist_builder.download_and_prepare()
datasets = mnist_builder.as_dataset(shuffle_files=False)
mnist_train_data = datasets['train']
mnist_test_data = datasets['test']

mnist_train = mnist_train_data.map(
    lambda item: 
    (tf.cast(item['image'], tf.float32)/255.0,
     tf.cast(item['label'], tf.int32))
)
mnist_test = mnist_test_data.map(
    lambda item: 
    (tf.cast(item['image'], tf.float32)/255.0, 
     tf.cast(item['label'], tf.int32))
)
tf.random.set_seed(1)
mnist_train = mnist_train.shuffle(
    buffer_size=64, 
    reshuffle_each_iteration=False
)

mnist_validate = mnist_test.take(10000).batch(64)
mnist_train = mnist_train.skip(10000).batch(64)
\end{lstlisting}

\subsubsection*{Aufbau des Netzes}
Das neuronale Netz soll zunächst gleich aufgebaut sein wie in Abbildung \ref{fig:CNNArchitecture} dargestellt. Dafür werden jeweils zwei Convolutional- und Subsampling-Layer benögigt\index{Convolutional Layer}\index{Subsampling Layer}, gefolgt von einem Flattening Layer\index{Flattening Layer} und zwei vollständig verbundenen Schichten\index{Versteckte Schicht}\index{Hidden Layer}.
\begin{lstlisting}[language=Python]
## Build Model
model = tf.keras.Sequential()

## Convolutional and Pooling Layers
model.add(tf.keras.layers.Conv2D(
    filters=8, 
    kernel_size=(3, 3), 
    strides=(1, 1), 
    padding='same', 
    data_format='channels_last', 
    name='conv1', 
    activation='relu'
))
model.add(tf.keras.layers.AveragePooling2D(
    pool_size=(2, 2), 
    name='pool1'
))
model.add(tf.keras.layers.Conv2D(
    filters=16, 
    kernel_size=(3, 3), 
    strides=(1, 1), 
    padding='same', 
    data_format='channels_last', 
    name='conv2', 
    activation='relu'
))
model.add(tf.keras.layers.AveragePooling2D(
    pool_size=(2, 2), 
    name='pool2'
))

## Flattening Layer
model.add(tf.keras.layers.Flatten())

## Fully Connected Layers
model.add(tf.keras.layers.Dense(
    units=1024, 
    name='fc1', 
    activation='relu'
))
model.add(tf.keras.layers.Dense(
    units=10, 
    name='fc2', 
    activation='softmax'
))

## Compile the Model
tf.random.set_seed(1)
model.build(input_shape=(None, 28, 28, 1))
model.compile(
    optimizer=tf.keras.optimizers.Adam(), 
    loss=tf.keras.losses.SparseCategoricalCrossentropy(), 
    metrics=['accuracy']
)
\end{lstlisting}

\subsubsection*{Training}
Das erzeugte neuronale Netz wird anschließend mit dem Methodenaufruf
\begin{lstlisting}[language=Python]
model.fit(
    mnist_train, 
    epochs=5, 
    validation_data=mnist_validate
)
\end{lstlisting}
trainiert. Die Anzahl der Trainingsiterationen, hier \textit{Epoche} genannt, ist dabei auf 5 begrenzt. 

\subsubsection*{Ergebnisse}
In Abbildung \ref{fig:TrainingComparison} sind die Trainingsverläufe dieses CNN's\index{Convolutional Neural Network}\index{Faltungsnetz} und eines herkömmlichen neuronalen Netzes\index{Neuronales Netz} über den Verlauf der fünf Epochen dargestellt. Es fällt auf, dass das herkömmliche neuronale Netz immer schlechter abschneidet als das CNN, auch nicht, wenn noch mehr Epochen erlaubt werden. Es sei jedoch angemerkt, dass eine hier erreichte Genauigkeit von etwa 98\% für ein einfaches, vollständig verbundenes neuronales Netz äußerst zufriedenstellend ist. Üblich sind Werte um etwa 90\%.

\begin{figure}[!h]
\centering
\begin{subfigure}{.49\textwidth}
\centering
\begin{tikzpicture}
\draw[->] (0, 0) -- (0, 5.5) node[below right] {Genauigkeit};
\draw[->] (0, 0) -- (4.5, 0) node[above left] {Epoche};

\draw[-] (-.15, 0) node[left] {0.95} -- (0, 0);
\draw[-] (-.15, 1) node[left] {0.96} -- (0, 1);
\draw[-] (-.15, 2) node[left] {0.97} -- (0, 2);
\draw[-] (-.15, 3) node[left] {0.98} -- (0, 3);
\draw[-] (-.15, 4) node[left] {0.99} -- (0, 4);
\draw[-] (-.15, 5) node[left] {1.00} -- (0, 5);

\draw[-] (0, -.15) node[below] {1} -- (0, 0);
\draw[-] (1, -.15) node[below] {2} -- (1, 0);
\draw[-] (2, -.15) node[below] {3} -- (2, 0);
\draw[-] (3, -.15) node[below] {4} -- (3, 0);
\draw[-] (4, -.15) node[below] {5} -- (4, 0);

\draw[-][red] (0, 2.88) -- (1, 3.12) -- (2, 3.31) -- (3, 3.73) -- (4, 3.71);
\end{tikzpicture}
\caption{CNN}
\label{fig:TrainingCNN}
\end{subfigure}
\begin{subfigure}{.49\textwidth}
\centering
\begin{tikzpicture}
\draw[->] (0, 0) -- (0, 5.5) node[below right] {Genauigkeit};
\draw[->] (0, 0) -- (4.5, 0) node[above left] {Epoche};

\draw[-] (-.15, 0) node[left] {0.95} -- (0, 0);
\draw[-] (-.15, 1) node[left] {0.96} -- (0, 1);
\draw[-] (-.15, 2) node[left] {0.97} -- (0, 2);
\draw[-] (-.15, 3) node[left] {0.98} -- (0, 3);
\draw[-] (-.15, 4) node[left] {0.99} -- (0, 4);
\draw[-] (-.15, 5) node[left] {1.00} -- (0, 5);

\draw[-] (0, -.15) node[below] {1} -- (0, 0);
\draw[-] (1, -.15) node[below] {2} -- (1, 0);
\draw[-] (2, -.15) node[below] {3} -- (2, 0);
\draw[-] (3, -.15) node[below] {4} -- (3, 0);
\draw[-] (4, -.15) node[below] {5} -- (4, 0);

\draw[-][red] (0, 1.65) -- (1, 2.51) -- (2, 2.56) -- (3, 2.61) -- (4, 2.5);
\end{tikzpicture}
\caption{FCNN}
\label{fig:TrainingFCNN}
\end{subfigure}
\caption{Trainingsverlauf eines CNN's (\ref{fig:TrainingCNN}) im Vergleich zu einem herkömmlichen neuronalen Netz (\ref{fig:TrainingFCNN})}
\label{fig:TrainingComparison}
\end{figure}

\subsubsection*{Code}
Der folgende Link verweist auf ein Notebook in Google Colab, welches u. A. das Ausführen von Python-Code in der Cloud ermöglicht.\\[5pt]
\footnotesize\url{https://colab.research.google.com/drive/1n-t1O-3lq-VovD4DCZmhpc9q8Ht4n4At}\\[5pt]
\qrcode{https://colab.research.google.com/drive/1n-t1O-3lq-VovD4DCZmhpc9q8Ht4n4At}

\bibliographystyle{gerplain}
\bibliography{refs}
\clearpage
\printindex
\end{document}